# Sistema de Competencia de Modelos AI

## Descripci√≥n General

Este sistema permite la competencia en tiempo real entre diferentes proveedores de modelos AI (Groq, OpenAI, Bing) para determinar cu√°l proporciona la mejor respuesta para cada consulta.

## Caracter√≠sticas Principales

### üèÜ Competencia de Modelos
- **Ejecuci√≥n Paralela**: Los modelos Groq y OpenAI se ejecutan simult√°neamente
- **Selecci√≥n Autom√°tica**: El sistema elige autom√°ticamente la mejor respuesta basada en velocidad y √©xito
- **M√©tricas de Rendimiento**: Seguimiento detallado de tiempos de respuesta y tasas de √©xito

### üîê Seguridad de Claves API
- **Encriptaci√≥n**: Las claves API pueden ser encriptadas usando AES-256
- **Contrase√±a Maestra**: Protecci√≥n adicional con contrase√±a del administrador
- **Gesti√≥n Segura**: Herramientas para encriptar/desencriptar claves

### üåê M√∫ltiples Proveedores
- **Groq**: Modelos DeepSeek, Meta, y otros
- **OpenAI**: GPT-4, GPT-4o-mini
- **Bing**: B√∫squeda web con s√≠ntesis de respuestas

## Configuraci√≥n

### Variables de Entorno

```bash
# Configuraci√≥n de modelos
GROQ_API_KEY=tu_clave_groq
OPENAI_API_KEY=tu_clave_openai
SEARCH_API_KEY=tu_clave_bing

# Modelo por defecto
DEFAULT_MODEL_PROVIDER=groq

# Encriptaci√≥n (opcional)
USE_ENCRYPTED_KEYS=false
MASTER_PASSWORD=tu_contrase√±a_segura
```

### Encriptaci√≥n de Claves

1. **Encriptar claves existentes**:
   ```bash
   python scripts/encrypt_keys.py
   ```

2. **Configurar variables encriptadas**:
   ```bash
   USE_ENCRYPTED_KEYS=true
   GROQ_API_KEY_ENCRYPTED=clave_encriptada_aqui
   OPENAI_API_KEY_ENCRYPTED=clave_encriptada_aqui
   SEARCH_API_KEY_ENCRYPTED=clave_encriptada_aqui
   ```

## Endpoints de la API

### üí¨ Chat Est√°ndar
```http
POST /chat
{
  "prompt": "Tu pregunta aqu√≠",
  "model_provider": "groq|openai|compete|bing",
  "temperature": 0.7
}
```

### üèÅ Competencia de Modelos
```http
POST /compete
{
  "prompt": "Tu pregunta aqu√≠",
  "temperature": 0.7
}
```

**Respuesta**:
```json
{
  "groq_response": "Respuesta de Groq",
  "openai_response": "Respuesta de OpenAI",
  "winning_response": "La mejor respuesta",
  "best_performer": "groq|openai",
  "performance_stats": {
    "groq_time": 1.2,
    "openai_time": 1.8,
    "total_time": 2.1
  }
}
```

### üìä Estad√≠sticas de Rendimiento
```http
GET /performance
```

## Uso del Sistema

### 1. Configuraci√≥n Inicial

```python
# Instalar dependencias
pip install -r requirements.txt

# Configurar variables de entorno
cp .env.example .env
# Editar .env con tus claves API
```

### 2. Encriptar Claves (Opcional)

```python
# Ejecutar script de encriptaci√≥n
python scripts/encrypt_keys.py

# Seguir las instrucciones para encriptar tus claves
# Actualizar .env con las claves encriptadas
```

### 3. Iniciar el Servidor

```bash
uvicorn servidor.main:app --reload --port 8000
```

### 4. Probar la Competencia

```bash
# Usando curl
curl -X POST "http://localhost:8000/compete" \
  -H "Content-Type: application/json" \
  -H "X-API-Key: tu_api_key" \
  -d '{"prompt": "Explica la inteligencia artificial", "temperature": 0.7}'
```

## Arquitectura del Sistema

### Componentes Principales

1. **ModelManager**: Gestiona m√∫ltiples proveedores de AI
2. **APIKeyEncryption**: Maneja la encriptaci√≥n/desencriptaci√≥n de claves
3. **GroqClient**: Cliente para modelos Groq
4. **OpenAIClient**: Cliente para modelos OpenAI
5. **BingClient**: Cliente para b√∫squeda web con Bing

### Flujo de Competencia

```
Usuario ‚Üí Endpoint /compete ‚Üí ModelManager ‚Üí [Groq + OpenAI] ‚Üí Evaluaci√≥n ‚Üí Mejor Respuesta
```

### Criterios de Selecci√≥n

1. **√âxito**: Respuestas sin errores tienen prioridad
2. **Velocidad**: Entre respuestas exitosas, se elige la m√°s r√°pida
3. **Calidad**: M√©tricas adicionales pueden ser implementadas

## Monitoreo y M√©tricas

### M√©tricas Rastreadas

- **Tiempo de Respuesta**: Latencia de cada modelo
- **Tasa de √âxito**: Porcentaje de respuestas exitosas
- **Errores**: Tipos y frecuencia de errores
- **Uso de Tokens**: Consumo por modelo

### Logs y Debugging

```python
# Configurar logging
import logging
logging.basicConfig(level=logging.INFO)

# Los logs incluyen:
# - Tiempos de respuesta
# - Errores de API
# - M√©tricas de competencia
```

## Mejores Pr√°cticas

### Seguridad

1. **Nunca** hardcodear claves API en el c√≥digo
2. Usar encriptaci√≥n para claves sensibles
3. Rotar claves API regularmente
4. Monitorear uso de API para detectar anomal√≠as

### Rendimiento

1. Implementar cache para respuestas frecuentes
2. Usar timeouts apropiados para evitar bloqueos
3. Monitorear l√≠mites de rate de las APIs
4. Implementar circuit breakers para APIs fallidas

### Escalabilidad

1. Usar async/await para operaciones concurrentes
2. Implementar pooling de conexiones
3. Considerar load balancing para m√∫ltiples instancias
4. Usar bases de datos para m√©tricas persistentes

## Troubleshooting

### Errores Comunes

1. **"Invalid API Key"**
   - Verificar que las claves est√©n correctamente configuradas
   - Si usa encriptaci√≥n, verificar la contrase√±a maestra

2. **"Model not available"**
   - Verificar que el proveedor est√© disponible
   - Revisar l√≠mites de rate de la API

3. **"Timeout errors"**
   - Ajustar timeouts en la configuraci√≥n
   - Verificar conectividad de red

### Debugging

```python
# Habilitar logs detallados
export LOG_LEVEL=DEBUG

# Verificar estado de APIs
curl http://localhost:8000/performance

# Probar claves individualmente
python -c "from servidor.model_manager import ModelManager; mm = ModelManager(); print(mm.get_available_providers())"
```

## Contribuci√≥n

Para contribuir al sistema:

1. Fork el repositorio
2. Crear una rama para tu feature
3. Implementar tests para nuevas funcionalidades
4. Enviar pull request con descripci√≥n detallada

## Licencia

Este proyecto est√° bajo licencia MIT. Ver archivo LICENSE para m√°s detalles.